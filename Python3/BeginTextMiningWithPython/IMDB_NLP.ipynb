{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "def review_to_wordlist(review):\n",
    "    review_text = BeautifulSoup(review).get_text()\n",
    "    \n",
    "    review_text = re.sub(\"[^a-zA-Z]\",\" \",review_text)\n",
    "    \n",
    "    words = review_text.lower().split()\n",
    "    return words\n",
    "\n",
    "train = pd.read_csv('/Users/Hanxiaoyang/IMDB_sentiment_analysis_data/labeledTrainData.tsv', header=0, delimiter=\"\\t\", quoting=3)\n",
    "test = pd.read_csv('/Users/Hanxiaoyang/IMDB_sentiment_analysis_data/testData.tsv', header=0, delimiter=\"\\t\", quoting=3 )\n",
    "\n",
    "\n",
    "y_train = train['sentiment']\n",
    "train_data =[]\n",
    "\n",
    "for i in range(0,len(train['review'])):\n",
    "    train_data.append(\" \".join(review_to_wordlist(train['review'][i])))\n",
    "\n",
    "test_data =[]\n",
    "\n",
    "for i in range(0,len(train['review'])):\n",
    "    test_data.append(\" \".join(review_to_wordlist(test['review'][i])))\n",
    "    \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer as tfidf\n",
    "\n",
    "tfv = tfidf(min_df=3,max_features=None,strip_accents='unicode',analyzer='word',\n",
    "            token_pattern=r'\\w{1,}', ngram_range=(1,2),use_idf=1,\n",
    "            smooth_idf=1,sublinear_tf=1,stop_words='english')\n",
    "\n",
    "X_all = train_data + test_data\n",
    "len_train = len(train_data)\n",
    "\n",
    "tfv.fit(X_all)\n",
    "X_all = tfv.transform(X_all)\n",
    "\n",
    "X_train = X_all[:len_train]\n",
    "X_test = X_all[len_train:]\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB as MNB\n",
    "\n",
    "model_NB = MNB()\n",
    "model_NB.fit(X, y_train) #特征数据直接灌进来\n",
    "MNB(alpha=1.0, class_prior=None, fit_prior=True)\n",
    "\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "import numpy as np\n",
    "\n",
    "print (\"多项式贝叶斯分类器20折交叉验证得分: \", np.mean(cross_val_score(model_NB, X, y_train, cv=20, scoring='roc_auc')))\n",
    "# 多项式贝叶斯分类器20折交叉验证得分: 0.950837239\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression as LR\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "# 设定grid search的参数\n",
    "grid_values = {'C':[30]}\n",
    "# 设定打分为roc_auc\n",
    "model_LR = GridSearchCV(LR(penalty = 'L2', dual = True, random_state = 0), grid_values, scoring = 'roc_auc', cv = 20)\n",
    "# 数据灌进来\n",
    "model_LR.fit(X,y_train)\n",
    "# 20折交叉验证，开始漫长的等待...\n",
    "GridSearchCV(cv=20, estimator=LogisticRegression(C=1.0, class_weight=None, dual=True,\n",
    "                                                 fit_intercept=True, intercept_scaling=1, penalty='L2', random_state=0, tol=0.0001),\n",
    "             fit_params={}, iid=True, loss_func=None, n_jobs=1,\n",
    "             param_grid={'C': [30]}, pre_dispatch='2*n_jobs', refit=True,\n",
    "             score_func=None, scoring='roc_auc', verbose=0)\n",
    "#输出结果\n",
    "print (model_LR.grid_scores_)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}